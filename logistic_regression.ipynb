{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 578 ms, sys: 362 ms, total: 940 ms\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "db = MongoClient('mongodb://143.215.138.132:27017')['big_data']\n",
    "\n",
    "matchNE = {'$match': {'lat': {'$gte': 36, '$lte': 50}, 'lon': {'$gte': -99, '$lte': -69}}}\n",
    "matchSE = {'$match': {'lat': {'$gte': 25, '$lte': 36}, 'lon': {'$gte': -99, '$lte': -69}}}\n",
    "matchNW = {'$match': {'lat': {'$gte': 36, '$lte': 50}, 'lon': {'$gte': -125, '$lte': -99}}}\n",
    "matchSW = {'$match': {'lat': {'$gte': 25, '$lte': 36}, 'lon': {'$gte': -125, '$lte': -99}}}\n",
    "\n",
    "sentence_list = []\n",
    "location_list = []\n",
    "\n",
    "limit = {'$limit': 10000}\n",
    "\n",
    "pipeline = [matchNE, limit]\n",
    "\n",
    "for tweet in db.tweet.aggregate(pipeline):\n",
    "    sentence_list.append(tweet['text'])\n",
    "    location_list.append('NE')\n",
    "\n",
    "pipeline = [matchSE, limit]\n",
    "\n",
    "for tweet in db.tweet.aggregate(pipeline):\n",
    "    sentence_list.append(tweet['text'])\n",
    "    location_list.append('SE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add your own sentence here\n",
    "your_sentence = \"Georgia Tech is in Atlanta\"\n",
    "sentence_list.append(your_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tweet_Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = TweetTokenizer()\n",
    "    def __call__(self, doc):\n",
    "        return self.wnl.tokenize(doc)\n",
    "\n",
    "def make_features(corpus):\n",
    "    vectorizer = CountVectorizer(tokenizer=Tweet_Tokenizer(), analyzer='word', min_df=0)\n",
    "    return vectorizer.fit_transform(corpus), vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 s, sys: 14.5 ms, total: 1.29 s\n",
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentence_vector_list, vector_name_list = make_features(sentence_list)\n",
    "your_sentence_vector = sentence_vector_list[-1]\n",
    "sentence_vector_list = sentence_vector_list[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_vectors, test_vectors, training_locations, test_locations =\\\n",
    "    train_test_split(sentence_vector_list, location_list, test_size=0.1, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(solver='saga', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.66 s, sys: 39.2 ms, total: 8.7 s\n",
      "Wall time: 8.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='saga', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr_clf.fit(training_vectors, training_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 975 µs, sys: 641 µs, total: 1.62 ms\n",
      "Wall time: 813 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_test_locations = lr_clf.predict(test_vectors)\n",
    "predicted_your_sentence_location = lr_clf.predict(your_sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.603\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set accuracy: \"\\\n",
    "      + str(accuracy_score(test_locations, predicted_test_locations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of your sentence: ['SE']\n"
     ]
    }
   ],
   "source": [
    "print(\"Result of your sentence: \" + str(predicted_your_sentence_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = lr_clf.coef_[0]\n",
    "weights = dict()\n",
    "for vector, weight in zip(vector_name_list, theta):\n",
    "    weights[vector] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "houston\t2.03916361516\n",
      "@taylorswift13\t1.93280219125\n",
      "opening\t1.78577776519\n",
      "tx\t1.78154344494\n",
      "@negrosubversive\t1.77534699241\n",
      "fl\t1.76651045191\n",
      "@gibson326\t1.75794252108\n",
      "texas\t1.69164415998\n",
      "alabama\t1.69099897328\n",
      "#ghc16\t1.45043592821\n",
      "atlanta\t1.41609021516\n",
      "ion\t1.3549924556\n",
      "orleans\t1.35029390226\n",
      "@55mmbae\t1.33068500622\n",
      "polls\t1.32811055879\n",
      "mama\t1.28135215608\n",
      "#okctraffic\t1.27782500367\n",
      "austin\t1.270749194\n",
      "charlotte\t1.25774493567\n",
      "fw\t1.25456685261\n",
      "sc\t1.22913620726\n",
      "nc\t1.21543019297\n",
      "🤒\t1.2098019497\n",
      "beach\t1.2004184629\n",
      "@katramsland\t1.19926783846\n",
      "#1gottago\t1.18522323322\n",
      "@mycfe\t1.1843731842\n",
      "johnson\t1.16925587698\n",
      "hoe\t1.16024087735\n",
      "p\t1.15839373215\n",
      "☀\t1.15799621163\n",
      "whiskey\t1.15503614142\n",
      "folks\t1.15084046049\n",
      "raleigh\t1.14302668419\n",
      "aunt\t1.14244413643\n",
      "@khalifist\t1.11998556428\n",
      "yummy\t1.11877133136\n",
      "control\t1.10914421088\n",
      "@gavgordontogo\t1.10389939288\n",
      "mf\t1.0966530289\n",
      "bama\t1.09609304313\n",
      "police\t1.0864919358\n",
      "@thedonguru\t1.08510264994\n",
      "@iongviewing\t1.08482170696\n",
      "actions\t1.0796589564\n",
      "debate\t1.0781678393\n",
      "https://t.co/pialycdqdn\t1.07209363231\n",
      "due\t1.07079117309\n",
      "taylor\t1.06850619727\n",
      "gosh\t1.06744294494\n"
     ]
    }
   ],
   "source": [
    "top_vectors = sorted(weights, key=lambda x:weights[x], reverse=True)[:50]\n",
    "for vector_name in top_vectors:\n",
    "    print(str(vector_name) + '\\t' + str(weights[vector_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "york\t-1.57735428298\n",
      "cubs\t-1.57368724741\n",
      "ny\t-1.55998375532\n",
      "#specialreport\t-1.54442470785\n",
      "bars\t-1.44499905775\n",
      "#nyc\t-1.43483473118\n",
      "incident\t-1.40446169209\n",
      "toronto\t-1.38592934861\n",
      "missin\t-1.34203471149\n",
      "washington\t-1.33164338531\n",
      "within\t-1.32072387962\n",
      "detroit\t-1.31480376078\n",
      "nj\t-1.28324261706\n",
      "easier\t-1.27787772916\n",
      "@dineshdsouza\t-1.27743409063\n",
      "rather\t-1.25527050986\n",
      "ebay\t-1.24816515036\n",
      "howard\t-1.237592684\n",
      "@steff__r\t-1.22108434211\n",
      "wet\t-1.20139623436\n",
      "26\t-1.19576524609\n",
      "blind\t-1.19291275996\n",
      "xo\t-1.17857089658\n",
      "rain\t-1.16456081854\n",
      "@bottomoso\t-1.16395997575\n",
      "dc\t-1.16196697097\n",
      "window\t-1.15385707858\n",
      "waking\t-1.13980811632\n",
      "democratic\t-1.13090845181\n",
      "boone\t-1.13035143912\n",
      "warm\t-1.12288546166\n",
      "virginia\t-1.12002321119\n",
      "philly\t-1.11229393236\n",
      "michigan\t-1.10974738037\n",
      "rainy\t-1.10454054819\n",
      "answers\t-1.09252476786\n",
      "nyc\t-1.08823954012\n",
      "goin\t-1.08751517383\n",
      "purdue\t-1.0862995209\n",
      "#ictfl16\t-1.08047203777\n",
      "nope\t-1.0775590726\n",
      "#happyfriday\t-1.07660973141\n",
      "chuck\t-1.07247078973\n",
      "@dame_lillard\t-1.07150029319\n",
      "hahahaha\t-1.07045754172\n",
      "indiana\t-1.06653153537\n",
      "panera\t-1.06444313792\n",
      "🍂\t-1.05945858225\n",
      "rip\t-1.05539222196\n",
      "dating\t-1.052860592\n"
     ]
    }
   ],
   "source": [
    "top_vectors = sorted(weights, key=lambda x:weights[x], reverse=False)[:50]\n",
    "for vector_name in top_vectors:\n",
    "    print(str(vector_name) + '\\t' + str(weights[vector_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
