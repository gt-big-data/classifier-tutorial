{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.33 s, sys: 3.43 s, total: 8.76 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "db = MongoClient('mongodb://143.215.138.132:27017')['big_data']\n",
    "\n",
    "matchNE = {'$match': {'lat': {'$gte': 36, '$lte': 50}, 'lon': {'$gte': -99, '$lte': -69}}}\n",
    "matchSE = {'$match': {'lat': {'$gte': 25, '$lte': 36}, 'lon': {'$gte': -99, '$lte': -69}}}\n",
    "matchNW = {'$match': {'lat': {'$gte': 36, '$lte': 50}, 'lon': {'$gte': -125, '$lte': -99}}}\n",
    "matchSW = {'$match': {'lat': {'$gte': 25, '$lte': 36}, 'lon': {'$gte': -125, '$lte': -99}}}\n",
    "\n",
    "sentence_list = []\n",
    "location_list = []\n",
    "\n",
    "limit = {'$limit': 100000}\n",
    "\n",
    "pipeline = [matchNE, limit]\n",
    "\n",
    "for tweet in db.tweet.aggregate(pipeline):\n",
    "    sentence_list.append(tweet['text'])\n",
    "    location_list.append('NE')\n",
    "\n",
    "pipeline = [matchSE, limit]\n",
    "\n",
    "for tweet in db.tweet.aggregate(pipeline):\n",
    "    sentence_list.append(tweet['text'])\n",
    "    location_list.append('SE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add your own sentence here\n",
    "your_sentence = \"Georgia Tech is in Atlanta\"\n",
    "sentence_list.append(your_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tweet_Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = TweetTokenizer()\n",
    "    def __call__(self, doc):\n",
    "        return self.wnl.tokenize(doc)\n",
    "\n",
    "def make_features(corpus):\n",
    "    vectorizer = CountVectorizer(tokenizer=Tweet_Tokenizer(), analyzer='word', min_df=0)\n",
    "    return vectorizer.fit_transform(corpus), vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 110 ms, total: 11.1 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentence_vector_list, vector_name_list = make_features(sentence_list)\n",
    "your_sentence_vector = sentence_vector_list[-1]\n",
    "sentence_vector_list = sentence_vector_list[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_vectors, test_vectors, training_locations, test_locations =\\\n",
    "    train_test_split(sentence_vector_list, location_list, test_size=0.1, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(solver='saga', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 195 ms, total: 2min 45s\n",
      "Wall time: 2min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='saga', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr_clf.fit(training_vectors, training_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.02 ms, sys: 3.73 ms, total: 6.75 ms\n",
      "Wall time: 5.34 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_test_locations = lr_clf.predict(test_vectors)\n",
    "predicted_your_sentence_location = lr_clf.predict(your_sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.6623\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set accuracy: \"\\\n",
    "      + str(accuracy_score(test_locations, predicted_test_locations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of your sentence: ['SE']\n"
     ]
    }
   ],
   "source": [
    "print(\"Result of your sentence: \" + str(predicted_your_sentence_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = lr_clf.coef_[0]\n",
    "weights = dict()\n",
    "for vector, weight in zip(vector_name_list, theta):\n",
    "    weights[vector] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx\t4.07853329354\n",
      "#txhsfb\t3.38232510753\n",
      "fl\t3.17132681582\n",
      "@karn33333\t3.00236066592\n",
      "houston\t2.9703543303\n",
      "@negrosubversive\t2.92659874814\n",
      "jacksonville\t2.8080186635\n",
      "#tcprepzone\t2.7828139948\n",
      "#ghc16\t2.77569710474\n",
      "tampa\t2.76449383613\n",
      "#cubevenue\t2.67474070071\n",
      "alabama\t2.60666753058\n",
      "#hometeamfb\t2.58899386067\n",
      "orleans\t2.58200502859\n",
      "#alpreps\t2.48388829074\n",
      "orlando\t2.46893300019\n",
      "#dateline\t2.4220914986\n",
      "#dallas\t2.41539083607\n",
      "ga\t2.35231840945\n",
      "#arpreps\t2.34553786214\n",
      "@__kissesileft\t2.30779008797\n",
      "#hamildocpbs\t2.30672097748\n",
      "@osvarsity\t2.2870243328\n",
      "#memphis\t2.27998207796\n",
      "georgia\t2.23822461308\n",
      "#oklahomacity\t2.22140570574\n",
      "#bloodofsylas\t2.22126255519\n",
      "#gvlfootball\t2.18690641335\n",
      "greenville\t2.18547116131\n",
      "@do_confidence\t2.15306502591\n",
      "br\t2.11322241535\n",
      "#mspreps\t2.11157120974\n",
      "hhn\t2.10782879629\n",
      "#florida\t2.10466939442\n",
      "roos\t2.10225661968\n",
      "#wstc\t2.10053095835\n",
      "texas\t2.07922391169\n",
      "#preds\t2.0637977994\n",
      "fwy\t2.05507209141\n",
      "dallas\t2.05359048919\n",
      "dp\t2.04919796911\n",
      "huffman\t2.02922513666\n",
      "atlanta\t2.01419714718\n",
      "@lookatmechange\t2.01288915255\n",
      "@grinder_1833\t1.99909254356\n",
      "@dgarrick5534\t1.9964778361\n",
      "#houston\t1.99585672209\n",
      "@ogbarrybonds\t1.98694818427\n",
      "@gibson326\t1.98501661633\n",
      "@karensassybelle\t1.97836627662\n"
     ]
    }
   ],
   "source": [
    "top_vectors = sorted(weights, key=lambda x:weights[x], reverse=True)[:50]\n",
    "for vector_name in top_vectors:\n",
    "    print(str(vector_name) + '\\t' + str(weights[vector_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#wvprepfb\t-3.09928286231\n",
      "il\t-2.98630014062\n",
      "nj\t-2.90409547636\n",
      "mn\t-2.87648988857\n",
      "#nyc\t-2.68685094284\n",
      "#toronto\t-2.59433638934\n",
      "incident\t-2.58722860407\n",
      "md\t-2.49590550853\n",
      "@thsbluedevils\t-2.48198811616\n",
      "@benpage11benp\t-2.46034771432\n",
      "@ashcrofttom\t-2.34807087679\n",
      "ia\t-2.29496947421\n",
      "#isles\t-2.25631913525\n",
      "rainy\t-2.21877424729\n",
      "toronto\t-2.21118013732\n",
      "salem\t-2.20715776867\n",
      "wi\t-2.14873555434\n",
      "#wisfb\t-2.14668510867\n",
      "@mickersmith20\t-2.10185591986\n",
      "va\t-2.09213754566\n",
      "#chicago\t-2.04235528776\n",
      "#blackhawks\t-2.01278413269\n",
      "#iahsfb\t-2.00199307237\n",
      "@sandplague\t-1.99957545543\n",
      "pa\t-1.99559640312\n",
      "#nashville\t-1.99095340082\n",
      "cincinnati\t-1.98503736814\n",
      "@annaiya_ruffin\t-1.95725895692\n",
      "pennridge\t-1.95491294989\n",
      "@kalamazoowings\t-1.94828433865\n",
      "lebanon\t-1.94367524433\n",
      "@ellis_pemrick20\t-1.9268225726\n",
      "montreal\t-1.92010115881\n",
      "pittsburgh\t-1.91339560506\n",
      "manhattan\t-1.91227509705\n",
      "brooklyn\t-1.91150233072\n",
      "#boston\t-1.90868362113\n",
      "ontario\t-1.89892597328\n",
      "#newyork\t-1.89223492544\n",
      "@kanova\t-1.87069255662\n",
      "ks\t-1.85232012596\n",
      "philadelphia\t-1.84920783352\n",
      "middletown\t-1.84296010674\n",
      "#inspiration\t-1.8193261224\n",
      "orchard\t-1.81856414991\n",
      "baltimore\t-1.81471367871\n",
      "sectional\t-1.78830643469\n",
      "minnesota\t-1.77926449069\n",
      "massachusetts\t-1.77923496903\n",
      "@airekah_\t-1.77813862442\n"
     ]
    }
   ],
   "source": [
    "top_vectors = sorted(weights, key=lambda x:weights[x], reverse=False)[:50]\n",
    "for vector_name in top_vectors:\n",
    "    print(str(vector_name) + '\\t' + str(weights[vector_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find more in Chapter 1 and 2 of the book below\n",
    "# https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
